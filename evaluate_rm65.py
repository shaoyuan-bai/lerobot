#!/usr/bin/env python

# Copyright 2025 The HuggingFace Inc. team. All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
RM65 åŒè‡‚æœºå™¨äººæ¨ç†è„šæœ¬

ä½¿ç”¨è®­ç»ƒå¥½çš„ç­–ç•¥æ§åˆ¶ RM65 æœºå™¨äººæ‰§è¡Œä»»åŠ¡ã€‚

ç”¨æ³•ç¤ºä¾‹:
    python evaluate_rm65.py \
        --policy-path /home/woosh/bai/lerobot/outputs/train/rm65_pickup_xuebi1/checkpoints/last/pretrained_model \
        --num-episodes 5 \
        --fps 20
"""

import argparse
import logging
import time

import numpy as np
import torch

from lerobot.cameras.ffmpeg import FFmpegCameraConfig
from lerobot.policies.factory import make_pre_post_processors
from lerobot.processor import make_default_robot_action_processor
from lerobot.processor.converters import observation_to_transition, transition_to_batch
from lerobot.processor.core import TransitionKey
from lerobot.robots.bi_rm65_follower.config_bi_rm65_follower import BiRM65FollowerConfig
from lerobot.robots.bi_rm65_follower.bi_rm65_follower import BiRM65Follower
from lerobot.utils.control_utils import init_keyboard_listener
from lerobot.utils.robot_utils import busy_wait
from lerobot.utils.utils import init_logging, log_say
from lerobot.utils.visualization_utils import _init_rerun


def parse_args():
    parser = argparse.ArgumentParser(description="RM65 åŒè‡‚æœºå™¨äººç­–ç•¥æ¨ç†")
    parser.add_argument(
        "--policy-path",
        type=str,
        required=True,
        help="è®­ç»ƒå¥½çš„æ¨¡å‹è·¯å¾„ï¼ˆé€šå¸¸æ˜¯ checkpoints/last/pretrained_modelï¼‰",
    )
    parser.add_argument(
        "--num-episodes",
        type=int,
        default=5,
        help="æ‰§è¡Œçš„å›åˆæ•°é‡",
    )
    parser.add_argument(
        "--fps",
        type=int,
        default=20,
        help="æ§åˆ¶é¢‘ç‡ï¼ˆå¸§æ¯ç§’ï¼‰",
    )
    parser.add_argument(
        "--episode-time-s",
        type=int,
        default=60,
        help="æ¯ä¸ªå›åˆçš„æœ€å¤§æ—¶é•¿ï¼ˆç§’ï¼‰",
    )
    parser.add_argument(
        "--left-arm-ip",
        type=str,
        default="169.254.128.20",
        help="å·¦è‡‚ IP åœ°å€",
    )
    parser.add_argument(
        "--right-arm-ip",
        type=str,
        default="169.254.128.21",
        help="å³è‡‚ IP åœ°å€",
    )
    parser.add_argument(
        "--no-display",
        action="store_true",
        help="ç¦ç”¨ Rerun å¯è§†åŒ–",
    )
    parser.add_argument(
        "--no-sound",
        action="store_true",
        help="ç¦ç”¨è¯­éŸ³æç¤º",
    )
    return parser.parse_args()


def main():
    args = parse_args()
    init_logging()
    
    # å¯ç”¨ DEBUG çº§åˆ«æ—¥å¿—
    logging.getLogger("lerobot.robots").setLevel(logging.DEBUG)

    # åˆ›å»ºç›¸æœºé…ç½®ï¼ˆä½¿ç”¨ FFmpeg è·å–æ›´é«˜æ€§èƒ½ï¼‰
    camera_config = {
        "top": FFmpegCameraConfig(
            index_or_path="/dev/video0",
            width=1920,
            height=1080,
            fps=args.fps,
        ),
        "wrist": FFmpegCameraConfig(
            index_or_path="/dev/video2",
            width=1920,
            height=1080,
            fps=args.fps,
        ),
    }

    # åˆ›å»ºæœºå™¨äººé…ç½®
    robot_config = BiRM65FollowerConfig(
        left_arm_ip=args.left_arm_ip,
        right_arm_ip=args.right_arm_ip,
        cameras=camera_config,
        id="rm65_follower",
    )

    # å®ä¾‹åŒ–æœºå™¨äºº
    logging.info("æ­£åœ¨åˆå§‹åŒ– RM65 æœºå™¨äºº...")
    robot = BiRM65Follower(robot_config)

    # åŠ è½½è®­ç»ƒå¥½çš„ç­–ç•¥ï¼Œç¡®ä¿ä½¿ç”¨ GPU
    logging.info(f"æ­£åœ¨åŠ è½½ç­–ç•¥: {args.policy_path}")
    from lerobot.policies.act.modeling_act import ACTPolicy
    
    # ç¡®å®šè®¾å¤‡ï¼ˆä¸ä¾èµ– policy.config.deviceï¼‰
    device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
    logging.info(f"ğŸš€ Using device: {device}")
    
    # åŠ è½½æ¨¡å‹å¹¶ç§»åˆ°æŒ‡å®šè®¾å¤‡
    policy = ACTPolicy.from_pretrained(args.policy_path).to(device).eval()

    # åˆ›å»ºé¢„å¤„ç†å’Œåå¤„ç†å™¨ï¼ˆä½¿ç”¨ç¡®å®šçš„è®¾å¤‡ï¼‰
    preprocessor, postprocessor = make_pre_post_processors(
        policy_cfg=policy.config,
        pretrained_path=args.policy_path,
        preprocessor_overrides={"device_processor": {"device": str(device)}},
    )
    
    # DEBUG: æ‰“å° preprocessor çš„ç»“æ„
    logging.info(f"Preprocessor type: {type(preprocessor)}")
    logging.info(f"Preprocessor: {preprocessor}")
    if hasattr(preprocessor, 'steps'):
        logging.info(f"Preprocessor steps: {preprocessor.steps}")

    # åˆ›å»ºæœºå™¨äººåŠ¨ä½œå¤„ç†å™¨
    robot_action_processor = make_default_robot_action_processor()

    # è¿æ¥æœºå™¨äºº
    logging.info("æ­£åœ¨è¿æ¥æœºå™¨äºº...")
    robot.connect()

    if not robot.is_connected:
        raise RuntimeError("æœºå™¨äººè¿æ¥å¤±è´¥ï¼")

    # åˆå§‹åŒ–é”®ç›˜ç›‘å¬å’Œå¯è§†åŒ–
    listener, events = init_keyboard_listener()
    if not args.no_display:
        _init_rerun(session_name="rm65_evaluation")

    logging.info(f"å¼€å§‹æ‰§è¡Œç­–ç•¥æ¨ç†ï¼Œå…± {args.num_episodes} ä¸ªå›åˆ")
    logging.info("æŒ‰ Ctrl+C å¯éšæ—¶åœæ­¢")

    try:
        for episode_idx in range(args.num_episodes):
            log_say(f"æ‰§è¡Œç¬¬ {episode_idx + 1}/{args.num_episodes} ä¸ªå›åˆ", play_sounds=not args.no_sound)

            # é‡ç½®ç­–ç•¥çŠ¶æ€
            policy.reset()

            # æ‰§è¡Œä¸€ä¸ªå›åˆ
            start_time = time.time()
            frame_count = 0

            while time.time() - start_time < args.episode_time_s:
                loop_start = time.perf_counter()

                # è·å–æœºå™¨äººè§‚æµ‹
                t0 = time.perf_counter()
                robot_obs = robot.get_observation()
                t1 = time.perf_counter()
                
                # DEBUG: æ‰“å°è§‚æµ‹æ•°æ®ç»“æ„
                if frame_count == 0:
                    logging.info(f"Robot observation keys: {list(robot_obs.keys())}")
                    for key, value in robot_obs.items():
                        if isinstance(value, (torch.Tensor, np.ndarray)):
                            logging.info(f"  {key}: shape={getattr(value, 'shape', 'N/A')}, dtype={getattr(value, 'dtype', type(value))}")
                
                # è½¬æ¢ä¸ºç­–ç•¥æœŸæœ›çš„æ ¼å¼ï¼ˆä¸æ·»åŠ  batch ç»´åº¦ï¼Œè®© preprocessor å¤„ç†ï¼‰
                # 1. åˆå¹¶å…³èŠ‚ä½ç½®ä¸º state å‘é‡ (13ç»´: 12ä¸ªå…³èŠ‚ + 1ä¸ªå¤¹çˆªï¼Œä½†å¤¹çˆªæ€»æ˜¯0)
                joint_keys = [
                    'left_joint_1.pos', 'left_joint_2.pos', 'left_joint_3.pos',
                    'left_joint_4.pos', 'left_joint_5.pos', 'left_joint_6.pos',
                    'right_joint_1.pos', 'right_joint_2.pos', 'right_joint_3.pos',
                    'right_joint_4.pos', 'right_joint_5.pos', 'right_joint_6.pos',
                ]
                state_values = [robot_obs[key] for key in joint_keys]
                state_values.append(0.0)  # å¤¹çˆªå€¼ï¼Œæ€»æ˜¯0
                state = np.array(state_values, dtype=np.float32)
                
                # 2. é‡å‘½åå’Œè½¬æ¢å›¾åƒï¼ˆæ·»åŠ  "observation." å‰ç¼€ä»¥åŒ¹é…ç­–ç•¥æœŸæœ›ï¼‰
                observation = {}
                observation['observation.state'] = torch.from_numpy(state)  # (13,)
                
                # å›¾åƒéœ€è¦ä» (H, W, C) è½¬ä¸º (C, H, W)ï¼Œå¹¶æ·»åŠ  "observation." å‰ç¼€
                # åŒæ—¶è½¬æ¢ä¸º float32 å¹¶å½’ä¸€åŒ–åˆ° [0, 1] ä»¥åŒ¹é…è®­ç»ƒæ—¶çš„æ ¼å¼
                for robot_key, obs_key in [('top', 'observation.images.top'), ('wrist', 'observation.images.wrist')]:
                    img = robot_obs[robot_key]  # (480, 640, 3) uint8
                    if isinstance(img, np.ndarray):
                        img = torch.from_numpy(img)
                    # è½¬æ¢ä¸º (C, H, W) å¹¶è½¬ä¸º float32ï¼ŒèŒƒå›´ [0, 1]
                    img = img.permute(2, 0, 1).float() / 255.0  # (3, 480, 640) float32 in [0, 1]
                    observation[obs_key] = img

                # DEBUG: æ‰“å° observation é”®
                if frame_count == 0:
                    logging.info(f"Policy observation keys: {list(observation.keys())}")
                    for key, value in observation.items():
                        logging.info(f"  {key}: shape={value.shape}, dtype={value.dtype}")

                # è½¬æ¢ä¸º transition æ ¼å¼
                transition = observation_to_transition(observation)
                
                # DEBUG: æ‰“å° transition ç»“æ„
                if frame_count == 0:
                    logging.info(f"Transition keys: {list(transition.keys())}")
                    obs_in_transition = transition.get(TransitionKey.OBSERVATION)
                    if obs_in_transition:
                        logging.info(f"Transition observation keys: {list(obs_in_transition.keys())}")

                # å¤„ç†è§‚æµ‹å¹¶æ¨ç†åŠ¨ä½œ
                with torch.inference_mode():
                    # æœ€åä¸€æ¬¡æ£€æŸ¥ transition ç»“æ„
                    if frame_count == 0:
                        logging.info(f"Before preprocessor - transition type: {type(transition)}")
                        logging.info(f"Before preprocessor - has OBSERVATION key: {TransitionKey.OBSERVATION in transition}")
                        obs_check = transition.get(TransitionKey.OBSERVATION)
                        logging.info(f"Before preprocessor - observation value: {obs_check is not None and isinstance(obs_check, dict)}")
                        # æµ‹è¯• copy() è¡Œä¸º
                        test_copy = transition.copy()
                        logging.info(f"After copy - has OBSERVATION key: {TransitionKey.OBSERVATION in test_copy}")
                        logging.info(f"After copy - observation value: {test_copy.get(TransitionKey.OBSERVATION) is not None}")
                    
                    try:
                        # ç›´æ¥è°ƒç”¨ _forward è€Œä¸æ˜¯ __call__ï¼Œå› ä¸º __call__ ä¼šå…ˆè°ƒç”¨ to_transition
                        # è€Œæˆ‘ä»¬å·²ç»æœ‰äº† transition æ ¼å¼çš„æ•°æ®
                        processed_transition = preprocessor._forward(transition)
                    except ValueError as e:
                        logging.error(f"Preprocessor failed: {e}")
                        logging.error(f"Transition keys at error: {list(transition.keys())}")
                        logging.error(f"Transition[OBSERVATION]: {transition.get(TransitionKey.OBSERVATION)}")
                        raise
                    
                    # DEBUG: æ‰“å°å¤„ç†åçš„ observation é”®
                    if frame_count == 0:
                        processed_obs = processed_transition.get(TransitionKey.OBSERVATION)
                        if processed_obs:
                            logging.info(f"After preprocessor - observation keys: {list(processed_obs.keys())}")
                    
                    # è½¬å› batch æ ¼å¼ä»¥è·å– observation
                    processed_batch = transition_to_batch(processed_transition)
                    
                    # DEBUG: æ‰“å° batch é”®
                    if frame_count == 0:
                        logging.info(f"After transition_to_batch - batch keys: {list(processed_batch.keys())}")
                    
                    action = policy.select_action(processed_batch)
                    processed_action = postprocessor(action)
                
                t2 = time.perf_counter()

                # è½¬æ¢ä¸ºæœºå™¨äººåŠ¨ä½œæ ¼å¼
                # processed_action å¯èƒ½æ˜¯ Tensor æˆ– dict
                if isinstance(processed_action, torch.Tensor):
                    # å¦‚æœæ˜¯ Tensorï¼Œç§»é™¤ batch ç»´åº¦å¹¶è½¬ numpy
                    action_array = processed_action.squeeze(0).cpu().numpy()  # (13,)
                    
                    # RM65 åŒè‡‚æœºå™¨äººæœŸæœ›çš„åŠ¨ä½œæ ¼å¼ï¼š
                    # - å‰ 6 ä¸ªå€¼ï¼šå·¦è‡‚å…³èŠ‚è§’åº¦ (joint_1 åˆ° joint_6)
                    # - æ¥ä¸‹æ¥ 6 ä¸ªå€¼ï¼šå³è‡‚å…³èŠ‚è§’åº¦ (joint_1 åˆ° joint_6)
                    # - æœ€å 1 ä¸ªå€¼ï¼šå¤¹çˆªä½ç½®
                    robot_action = {}
                    
                    # å·¦è‡‚åŠ¨ä½œ (joint_1 åˆ° joint_6)
                    for i in range(6):
                        robot_action[f'left_joint_{i+1}.pos'] = float(action_array[i])
                    
                    # å³è‡‚åŠ¨ä½œ (joint_1 åˆ° joint_6)
                    for i in range(6):
                        robot_action[f'right_joint_{i+1}.pos'] = float(action_array[i+6])
                    
                    # å¤¹çˆªåŠ¨ä½œ (å¦‚æœä¸æ˜¯ 0)
                    if len(action_array) > 12 and action_array[12] != 0:
                        robot_action['right_gripper.pos'] = float(action_array[12])
                    
                    # DEBUG: æ‰“å°åŠ¨ä½œå­—å…¸
                    if frame_count == 0:
                        logging.info(f"Sending action with keys: {list(robot_action.keys())}")
                        logging.info(f"Action values (first 3): left=[{action_array[0]:.2f}, {action_array[1]:.2f}, {action_array[2]:.2f}], right=[{action_array[6]:.2f}, {action_array[7]:.2f}, {action_array[8]:.2f}]")
                    
                elif isinstance(processed_action, dict):
                    # å¦‚æœæ˜¯ dictï¼Œç§»é™¤æ¯ä¸ªå€¼çš„ batch ç»´åº¦
                    robot_action = {}
                    for key, value in processed_action.items():
                        if isinstance(value, torch.Tensor):
                            robot_action[key] = value.squeeze(0).cpu().numpy()
                        else:
                            robot_action[key] = value
                else:
                    raise ValueError(f"Unexpected processed_action type: {type(processed_action)}")

                # å‘é€åŠ¨ä½œåˆ°æœºå™¨äºº
                robot.send_action(robot_action)
                t3 = time.perf_counter()

                # å¸§ç‡æ§åˆ¶ï¼ˆä¿®æ­£è´Ÿç­‰å¾…å¡é¡¿ï¼‰
                frame_count += 1
                elapsed = time.perf_counter() - loop_start
                
                # æ¯ 50 å¸§æ‰“å°ä¸€æ¬¡åˆ†æ®µè®¡æ—¶
                if frame_count % 50 == 0:
                    logging.info(
                        f"å¸§ {frame_count}: obs={((t1-t0)*1000):.1f}ms, "
                        f"infer={((t2-t1)*1000):.1f}ms, "
                        f"act={((t3-t2)*1000):.1f}ms, "
                        f"total={((t3-t0)*1000):.1f}ms (ç›®æ ‡: {(1000/args.fps):.1f}ms)"
                    )
                
                # é¿å…"è´Ÿç­‰å¾…"é€ æˆçš„å¡é¡¿
                dt = (1.0 / args.fps) - elapsed
                if dt > 0:
                    busy_wait(dt)

                # æ£€æŸ¥æ˜¯å¦éœ€è¦æå‰é€€å‡º
                if events.get("stop_recording", False):
                    log_say("æ”¶åˆ°åœæ­¢ä¿¡å·", play_sounds=not args.no_sound)
                    break

            actual_fps = frame_count / (time.time() - start_time)
            logging.info(f"å›åˆ {episode_idx + 1} å®Œæˆï¼Œå®é™…å¸§ç‡: {actual_fps:.2f} fps")

            # å›åˆé—´æš‚åœ
            if episode_idx < args.num_episodes - 1:
                log_say("å‡†å¤‡ä¸‹ä¸€ä¸ªå›åˆï¼Œè¯·é‡ç½®ç¯å¢ƒ", play_sounds=not args.no_sound, blocking=True)
                time.sleep(2)

    except KeyboardInterrupt:
        logging.info("æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢...")

    finally:
        # æ¸…ç†èµ„æº
        logging.info("æ­£åœ¨æ–­å¼€æœºå™¨äººè¿æ¥...")
        robot.disconnect()
        if listener is not None:
            listener.stop()
        log_say("æ¨ç†å®Œæˆ", play_sounds=not args.no_sound)


if __name__ == "__main__":
    main()
